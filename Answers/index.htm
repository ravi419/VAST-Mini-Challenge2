<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:w="urn:schemas-microsoft-com:office:word" xmlns:m="http://schemas.microsoft.com/office/2004/12/omml" xmlns="http://www.w3.org/TR/REC-html40">

<head>
	<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
	<meta name=ProgId content=Word.Document>
	<meta name=Generator content="Microsoft Word 15">
	<meta name=Originator content="Microsoft Word 15">
	<link rel=File-List href="VAST%20Challenge%202020%20MC2%20Answer%20Sheet_files/filelist.xml">
	<title>This form is a web page which was created in MS WORD and therefore can be easily edited that way</title>
	<link rel=themeData href="VAST%20Challenge%202020%20MC2%20Answer%20Sheet_files/themedata.thmx">
	<link rel=colorSchemeMapping href="VAST%20Challenge%202020%20MC2%20Answer%20Sheet_files/colorschememapping.xml">
	<style>
		.mycontent{
					max-width: 70%;
					margin-left: auto;
					margin-right: auto;
					font-family: 'Montserrat';
					font-size: 18px;
					line-height: 1.7;
					padding-right: 15px;
					padding-left: 15px;}
				
		        .imagepart{
					max-width: 90%;
					margin: auto;}
		
				.interactiveImagePart{
					max-width: 100%;
					margin: auto;}
				
				.column {
					float: left;
					width: 48%;
					padding-right:10px;
					padding-top:15px;
					padding-bottom:15px;}
		        		
		        /* Clear floats after image containers */
				.row::after {
					content: "";
					clear: both;
					display: table;
					padding-top:-100px}
				
				.ifrclss{
					width:60%;
					height:70%;
					margin-top:2%;}
				
				.ifnetworksmallclss{
					width:60%;
					height:60%;
					margin:2%;}
				
				.ifnetworkclss{
					width:70%;
					height:90%;
					margin-top:2%;
					margin-bottom:2%;}
		
				iftwobarplt{
					width:30%;
					height:60%;
					margin-top:2%;}
				
				.ifrbarplt{
					width:100%;					
					height:100%;
					margin-top:2%;
					margin-bottom:2%;}
				
				.figcls{
					text-align:center;
					margin-top:-0.5%;
					margin-bottom:2%;}
				
				.headerSection{
					max-width:auto}
	</style>
</head>

<body lang=EN-US link=blue vlink=purple style='tab-interval:.5in'>
	<div class="headerSection">
		<h2 align=center style='margin:0in;margin-bottom:.0001pt;text-align:center'>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;font-weight:normal;mso-bidi-font-weight:bold'>
				Entry Name:
				<span style='mso-spacerun:yes'> </span>
			</span>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:yellow'>
				&quot;OVGU-Chennaboina-MC2&quot;
			</span>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
				<o:p></o:p>
			</span>
		</h2>
		<h2 align=center style='margin:0in;margin-bottom:.0001pt;text-align:center'>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
				VAST Challenge
			</span>
			<i>
				<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:white;mso-bidi-font-weight:normal'>
					2020
				</span>
			</i>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin'>
				<br>
				<u>Mini-Challenge 2</u>
				<o:p></o:p>
			</span>
		</h2>
		<h3 style='margin:0in;margin-bottom:.0001pt'><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:
"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
			<o:p>&nbsp;</o:p>
			</span>
		</h3>
		<h3 style='margin:0in;margin-bottom:.0001pt'><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:
"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
			<o:p>&nbsp;</o:p>
			</span>
		</h3>
		<h3 style='margin:0in;margin-bottom:.0001pt'>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
				Team Members:
				<o:p></o:p>
			</span>
		</h3>
		<h3 style='margin:0in;margin-bottom:.0001pt'>
			<i style='mso-bidi-font-style:normal'>
				<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:yellow;mso-highlight:white;font-weight:normal;mso-bidi-font-weight:bold'>
					<span style='mso-spacerun:yes'>  </span>
					<o:p></o:p>
				</span>
			</i>
		</h3>
		
		<p class=MsoNormal>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:yellow;mso-bidi-font-style:italic'>
				Ravi Mallikarjun, Otto-von Guericke University, Magdeburg,
			</span>
			<a href="mailto:ravi.chennaboina@st.ovgu.de">
				<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:yellow;mso-bidi-font-style:italic'>
					ravi.chennaboina@st.ovgu.de
				</span>
			</a>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:yellow;mso-bidi-font-style:italic'>
				&nbsp;&nbsp;PRIMARY
			</span>
			<br/>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:yellow;mso-bidi-font-style:italic'>
				Niha Mohanty, Otto-von Guericke University, Magdeburg,
			</span>
			<a href="mailto:niha.mohanty@ovgu.de">
				<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:yellow;mso-bidi-font-style:italic'>
					niha.mohanty@ovgu.de
				</span>
			</a>
			<!-- <span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:yellow;mso-highlight:yellow;mso-bidi-font-style:italic'> </span>
			<i>
				<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
					<br/><br/>
					Under Supervision of : Dr. Monique Meuschke, Otto-von Guericke University Magdeburg
					<br style='mso-special-character:line-break'>
					<![if !supportLineBreakNewLine]><br style='mso-special-character:line-break'>
					<![endif]>
				</span>
			</i>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
				<o:p></o:p>
			</span> -->
		</p>
		<p class=MsoNormal>
			<b style='mso-bidi-font-weight:normal'>
				<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
					Student Team:
				</span>
			</b>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'> 
				<b style='mso-bidi-font-weight:normal'>
					<span style='mso-spacerun:yes'> </span>
			</b>	<i style='mso-bidi-font-style:normal'>
					<span style='background:white;mso-highlight:yellow'>
						YES 
					</span>
					<o:p></o:p>
				</i>
			</span>
		</p>
		
		<h3 style='margin:0in;margin-bottom:.0001pt'>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
				Tools Used:
				<o:p></o:p>
			</span>
		</h3>
		
		<p class=MsoNormal>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:white;mso-bidi-font-style:italic'>
				Python
				<o:p></o:p>
			</span>
		</p>
		<p class=MsoNormal>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:white;mso-bidi-font-style:italic'>
				R Programming 
				<o:p></o:p>
			</span>
		</p>
		<p class=MsoNormal>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:white;mso-bidi-font-style:italic'>
				Plotly
				<o:p></o:p>
			</span>
		</p>
		<p class=MsoNormal>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:yellow;mso-bidi-font-style:italic'>
				Bokeh library for interactive Visualisation and Networkx for Edge, Node graphs. 
			</span>
			<br/><br/>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:yellow;mso-bidi-font-style:italic; width:90%'>
				We also created an application for drawing the bounding box and giving the corresponding label to it. The basic structure was taken from a online source. We modified the application with more advanced features and we also tried integrated it with the python code which calculates the correct classification and incorrect classifications.
				<br/><br/>
				Referce to the source code of basic structure:
			</span>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;background:white;mso-highlight:yellow'>
				<a href="https://github.com/tzutalin/labelImg">
					<b style='mso-bidi-font-weight:normal'>
						https://github.com/tzutalin/labelImg
					</b>
				</a>
			</span>
			<br/><br/>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:yellow;mso-bidi-font-style:italic; width:90%'>
				
				Referce to our source code ,you can find it in BBoxLabeling folder:
			</span>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;background:white;mso-highlight:yellow'>
				<a href="https://github.com/ravi419/VAST-Mini-Challenge2">
					<b style='mso-bidi-font-weight:normal'>
						https://github.com/ravi419/VAST-Mini-Challenge2
					</b>
				</a>
			</span>
			
		</p>
		
		<p class=MsoNormal>
			<b style='mso-bidi-font-weight:normal'>
				<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;mso-bidi-font-style:italic'>
					Approximately how many hours were spent working on this submission in total?
				</span>
				<i style='mso-bidi-font-style:normal'>
					<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:yellow'>
						80 hrs
					</span>
				</i>
			</b>
		</p>
		
		<p class=MsoNormal>
			<b style='mso-bidi-font-weight:normal'>
				<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;mso-bidi-font-style:italic'>
					May we post your submission in the Visual Analytics Benchmark Repository after VAST Challenge 2020 is complete?
				</span>
			</b>
			<i style='mso-bidi-font-style:normal'>
				<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:yellow'>
					YES
				</span>
			</i>
		</p>
		
		<p class=MsoNormal>
			<b>
				<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;mso-bidi-font-style:italic'>
					Video
					<o:p></o:p>
				</span>
			</b>
			<i style='mso-bidi-font-style:normal'>
				<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:yellow'>
					The link to the video are:
				</span>
			</i>
		</p>
		
		<p class=MsoNormal>
			<a href="https://youtu.be/jUbEe1US5cw"> <!-- Paste here the video link -->
				<b style='mso-bidi-font-weight:normal'>
					<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:yellow'>
						https://youtu.be/jUbEe1US5cw <!-- Paste here the video link -->
					</span>
				</b>
			</a>
			<br><br>
			<a href="https://github.com/ravi419/VAST-Mini-Challenge2/tree/master/ScreenCast"> <!-- Paste here the video link -->
				<b style='mso-bidi-font-weight:normal'>
					<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:yellow'>
						https://github.com/ravi419/VAST-Mini-Challenge2/tree/master/ScreenCast<!-- Paste here the video link -->
					</span>
				</b>
			</a>
		</p>
		
		<div style='mso-element:para-border-div;border:none;border-bottom:solid windowtext 1.0pt;mso-border-bottom-alt:solid windowtext .75pt;padding:0in 0in 1.0pt 0in'>
			<p class=MsoNormal style='border:none;mso-border-bottom-alt:solid windowtext .75pt;padding:0in;mso-padding-alt:0in 0in 1.0pt 0in'>
				<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
					<o:p>&nbsp;</o:p>
				</span>
			</p>
		</div>
		
		<p class=MsoNormal>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
				<o:p>&nbsp;</o:p>
			</span>
		</p>
		<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'>
			<b style='mso-bidi-font-weight:normal'>
				<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;color:windowtext'>
					<div class="mycontent">
						Questions:
						<br/><br/>
						Given the images and text files as well as machine learning outputs, use visual analytics to answer the questions below to improve and understand machine learning outputs and track provenance, uncertainty, and confidence in machine learning results. Ultimately, you must link multiple data types to identify the group CGCS is seeking.
					</div>
				</span>
			</b>
		</p>
		<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;margin-left:.25in;background:white'>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
				<span style='mso-spacerun:yes'> </span>
			</span>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin;color:windowtext;mso-color-alt:windowtext'>
				<o:p></o:p>
			</span>
		</p>
		<br>
		<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;margin-left:.25in;background:white'>
			<b style='mso-bidi-font-weight:normal'>
				<i style='mso-bidi-font-style:normal'>
					<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:white'>
						<div class="mycontent">
							1. Examine the outputs from the model - either from the detection results provided or the results from a model you chose. Which objects were identified well by the model and which were not? Please limit your answer to 5 images and 250 words.
						</div>
					</span>
				</i>
			</b>
		</p>
		<br>
		<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;margin-left:.25in;background:white'>	
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
				<div class="mycontent">
					We have used the YOLO algorithm output to examine the results:
					<br>
					<b>Approach:</b> To examine any outcome, there should exist a <i>Ground Truth</i>. In order to generate the ground truth, we created a bounding box Labeling application through which we have labeled all the 40 person's images manually ,the application outputs a csv file containing the BoundingBox mesurements i.e x, y points and width, height of the box along with the corresponding label and filename.
					<br/><br/>
					Firstly, we compare the distribution of the labels accross the YOLO algorithm and the manually labeled files.
				</div>
				
				<div class="imagepart">
					<center>
						<iframe class="ifrbarplt" src="Plots/Counts_Of_Yolo_Predictions.html" ></iframe>
						<figcaption><b><i> Figure 1.1 Yolo prediction count of each object.</i></b></figcaption>
						<iframe class="ifrbarplt" src="Plots/Counts_Of_Manual_Predictions.html" ></iframe>
						<figcaption><b><i> Figure 1.2 Manual prediction count of each object.</i></b></figcaption>
					</center>
				</div>
				
				<div class="mycontent">
					After comparing Figure 1.1 and Figure 1.2, we can clearly see that YOLO algorithm did not classify few object class labeles such as BrownDie, FoamDart, GiftBag etc.
					<br/><br/>
					Secondly, we check the number of times an object label is misclassified by the YOLO algorithm. Here, we use the confusion matrix to show the misclassification of an object.
				</div>
				
				<div class="imagepart">
					<center>
						<figure>
							<img src="Images/ConfusionMatrix_Actual_VS_Predicted.png" alt=" Count of YOLO predicted Lables vs Count of Manually Assigned Lables" 
								 style="width:130%; margin-left:-15%;">
							<figcaption><b><i> Figure 1.3 Confusion matrix representation of missclassifications. </i></b></figcaption>
						</figure>
					</center>
				</div>
				
				<div class="mycontent">
					From the above heatmap we can see the number of times an actual label is misclassified by the YOLO algorithm. The most misclassified objects by YOLO are paperPlate as pumpkinNotes and partyFavor as cloudSign. Lets inspect the reason behind the missclassifications:
					
					<ul>
						<li> The Figure 1.3 shows us, that paperPlate has been misclassified 82 times as pumpkinNotes. The given images (Figure 1.4(a) &ampsand; Figure 1.4(b)) below shows us the comparison between paperPlate and pumpkinNotes. The reason for this misclassification could be the smiley face on both the images.</li>
					</ul>
				</div>
				
				<div class="imagepart">
					<center>
						<div class="row">
							<div class="column">
								<img src="Images/paperPlate.png" alt="paperPlate" style="width:70%;">
								<figcaption><b><i> Figure 1.4(a) paperPlate</i></b></figcaption>
							</div>
							<div class="column">
								<img src="Images/pumpkinNotes.png" alt="pumpkinNotes" style="width:70%; height:60%;">
								<figcaption><b><i> Figure 1.4(b) pumpkinNotes</i></b></figcaption>
							</div>
						</div>
					</center>
				</div>
				
				<div class="imagepart">
					<center>
						<div class="row">
							<div class="column">
								<img src="Images/partyFavor.jpg" alt="partyFavor" style="width:100%">
								<figcaption><b><i> Figure 1.5(a) partyFavor</i></b></figcaption>
							</div>
							<div class="column">
								<img src="Images/cloudSign.jpg" alt="cloudSign" style="width:100%">
								<figcaption><b><i> Figure 1.5(b) cloudSign</i></b></figcaption>
							</div>
						</div>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>
						<li> The Figure 1.3 shows us, that partyFavor has been misclassified 81 times as cloudSign. The given images (Figure 1.5(a) &ampsand; Figure 1.5(b)) above shows us the comparison between partyFavor and cloudSign. The reason for this misclassification could be the golden glitters present on the cloudSign.</li>
					</ul>
					Further, we tried to visualise the objects that are correctly and incorrectly classified in the images by the YOLO algorithm.
				</div>
			</span>
		</p>
		<br/>
		<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;margin-left:.25in;background:white'>
			<b style='mso-bidi-font-weight:normal'>
				<i style='mso-bidi-font-style:normal'>
					<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:white'>
						<div class="mycontent">
							2. Demonstrate your process for using visual analytics to correct for classification errors in the results. How do you represent confidence and uncertainty? How could the correction process be made more efficient? Please limit your answer to 10 images and 500 words.
						</div>
					</span>
				</i>
			</b>
		</p>
		<br>
		<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;margin-left:.25in;background:white'>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
				<div class="mycontent">
					With the <i>Groud Truth</i> that we prepared earlier, we followed the followed certain analysis steps to determine the classification errors and correcting the missclassifications by our tool.
					<ul>
						<li>After merging the all 40 person's data into a single dataframe, we are checking each person's file with the corresponding <i>Ground Truth</i> file person's name. If the ground truth label matches with the YOLO algorithm labels, then we are examining the area of intersection of the YOLO classified image's bounding box dimentions with the respective <i>Ground Truth</i> (manually labeled) image bounding box dimensions. This we are performing to increase the certainity of the process. Figure 2.1 shows bounding boxes of YOLO classifier and manually labeled. </li>
					</ul>
				</div>
				
				<div class="imagepart">
					<center>
						<img src="Images/YellowBallon.png" alt="Snow" style="width:70%; height:80%">
						<figcaption><b><i> Figure 2.1 Yellow Baloon</i></b></figcaption>
						<i>
							<ul>
								<li> Blue bounding box: Yolo Classified BBox. </li>
								<li> Green bounding box: Manually Classified BBox. </li>
							</ul>
						</i>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>						
						<li>We have used Shape library in Python which compares two polygon shapes and results in the area of intersection of both the BoundingBoxes. Here, we have set the criteria of 30%. Here, we choose to have a low threshold because sometimes the YOLO algorithm draws/detects the bounding box over only a portion of the actual object and we choose to consider such cases as good cases. We also tried even lower thresholds, but there was no significant improvement in the number of good cases, so we set the threshold at 30%.
							<ul>
								<li> If the intersection area of manually labeled bounding box to the YOLO labeled bounding box is greater than 30%, then we declare that the Image is correctly classified by the YOLO and we store the label and its count in a dataframe. </li>
								<li> If the intersection area is less than 30%, we say that the label is missclassified by YOLO algorithm and we store the resultant label in dataframe. Below we can see the count of correct, incorrect classified labels (Figure 2.2) and respective correctly, incorrectly classified image count (Figure 2.3). </li>
							</ul>
						</li>
					</ul>
				</div>
				
				<div class="imagepart">								
					<center>
						<iframe class="ifrbarplt" src="Plots/YOLO_Classified_Labels.html" style="width:60%; height:80%"></iframe>
						<figcaption><b><i> Figure 2.2 Correct classified lables vs. Missclassified lables count. </i></b></figcaption>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>
						<ul>
							<li> From the above image we can see the YOLO classified and missclassified labels count, count of correctly classified labels are 516 vs. incorrectly classified labeles are 2493. </li>
						</ul>
					</ul>
				</div>
				
				<div class="imagepart">
					<center>
						<iframe class="ifrbarplt" src="Plots/YOLO_Classified_Images.html" style="width:60%; height:80%"></iframe>
						<figcaption><b><i> Figure 2.3 Manual image files vs. Yolo image files count. </i></b></figcaption>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>
						<ul>
							<li> From the above image we can see YOLO files (images) count. The count of images which are classified correctly are 223 vs. incorrect classifications are 711. </li>
						</ul>
						
						<li> After examining the above results, we tried to run the analysis again, now setting the criteria as 0% but the count was the same, for both the labels and image files. Therefore we can say that the dimensions of correctly classified labels are correct. </li>
						
						<li> Further, we analyzed the distribution of correctly classified bounding box and labels with the incorrectly classified labels but correct bounding box dimensions, along with bounding box completely not detected in a pie chart as shown below, </li>
					</ul>
				</div>
				
				<div class="imagepart">
					<center>
						<iframe class="ifrclss" src="Plots/Pie_Chart_BB_Detection_Distrubution.html" ></iframe>
						<figcaption><b><i> Figure 2.4 Pie Chart for bounding box detection distribution. </i></b></figcaption>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>
						<li> With the above analysis information we plotted a bar chart where we can see the number of correctly and incorrectly classified results. The bar chart below shows the performance of the YOLO algorithm. </li>
					</ul>
				</div>
				
				<div class="imagepart">
					<center>
						<iframe class="ifrbarplt" src="Plots/Good_vs_Poor_Classification.html" ></iframe>
						<figcaption><b><i> Figure 2.5 Good vs. Poor classification. </i></b></figcaption>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>
						<li>To correct the classification errors, we have created an interactive application for the users. This application:
							<ul>
								<li> Allows the user to browse to the directory of the images. </li>
								<li> Displays the list of missclassified files to the user. </li>
								<li> When the first image is loaded on the canvas, its corresponding YOLO classified labels are also projected on the image along with the bounding box measurements.
								<li> The bounding boxes are color-coded to give them a distinction mark. </li>
								<li> On the right side of the application, the label names of those color encoded bounding box are shown. </li>
								<li> The user has complete access to the bounding boxes. The user can perform the following operations:
									<ul>
										<li> <b> DRAW - </b>If there are no bounding boxes detected by the YOLO Algorithm on an image, the user can draw one and label it accordingly. </li>
										<li> <b> DELETE - </b>If there are irrelevant bounding boxes, the user can delete them.</li>
										<li> <b> RESIZE - </b>If the bounding boxes are not of accurate size given to the image, the user re-size them.</li>
										<li> <b> EDIT - </b>If the user gave a wrong label name to a drawn bounding box, then he/she can re-lable it by editing the labels.</li>
									</ul>
								</li>
								<li> Once the image is labeled, the filename, bounding box and the label are stored in the csv file from which it has been fetched. </li>
								<li> We provide an option for the user to run the above discussed analysis and the result will be the increase in Correct classifications by one. </li>
								<li> The application also has the provision of zooming (+/-) the images to give better insight on the image. </li>
							</ul>
						</li>
					</ul>
				</div>
			</span>
		</p>
		<br/>
		<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;margin-left:.25in;background:white'>
			<b style='mso-bidi-font-weight:normal'>
				<i style='mso-bidi-font-style:normal'>
					<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:white'>
						<div class="mycontent">
							3. Characterize the distribution of objects across the forty people.
						</div>
						<br/>
						<div class="mycontent">
							A) Which people have which objects? Please limit your answer to 8 images and 250 words.
						</div>
					</span>
				</i>
			</b>
		</p>
		<br>
		<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;margin-left:.25in;background:white'>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
				<div class="mycontent">
					To analyse the object to person's distribution we used wordcloud library in python. The process is discussed below.
					<ol>
						<li> From the manually classified data we extracted persons data along with the objects (labels) and number of times the label linked to that person. </li>
						<li> Store the labels in a list along with multiple occurances. </li>
						<li> Join all the elements in the list and convert the joined elements into a single string. </li>
						<li> Pass the joined string into the WordCloud library and generate the WordCloud plot. </li>
						<li> Repeat the process from step one over all 40 persons and store it in a directory. </li>
					</ol>
				</div>
					
				<div class="mycontent">
					<ul>
						<li>The image below represents the WordCloud distribution accross first six persons </li>
					</ul>
				</div>
				
				<div class="imagepart">
					<center>
						<img src="Images/WordCloud_1-6Persons.png" alt="word cloud for first six person" style="width:100%">
						<figcaption><b><i>Figure 3(a).1 WordClouds representations of labels accociated to Person1 - Person6. </i></b></figcaption>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>
						<ul>
							<li>From the above image we can see that WordCloud represents the maximum occured label with a big font size .Therefore, we can see, Person1 has trophy as maximum occured word, whereas Person2 has almost even distribution of the labels <i>etc.</i> </li>
						</ul>
						
						<li>The image below represents the WordCloud distribution accross second six persons. </li>
					</ul>
				</div>
				
				<div class="imagepart">
					<center>
						<img src="Images/WordCloud_6-12Persons.png" alt="Snow" style="width:100%">
						<figcaption><b><i>Figure 3(a).2 WordClouds representations of labels accociated to Person7 - Person12. </i></b></figcaption>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>
						<ul>
							<li>From the WordCloud image of Person12 we can see less associated labels but relatively high occurances.</li>
						</ul>

						<li>The image below represents the WordCloud distribution accross next six persons. </li>
					</ul>
				</div>
				
				<div class="imagepart">
					<center>
						<img src="Images/WordCloud_12-18Persons.png" alt="Snow" style="width:100%">
						<figcaption><b><i>Figure 3(a).3 WordClouds representations of labels accociated to Person13 - Person18. </i></b></figcaption>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>
						<ul>
							<li>The Person15 has more labels associated but with relatively low occurances. </li>
						</ul>

						<li>The image below represents the WordCloud distribution accross further next six persons. </li>
					</ul>
				</div>

				<div class="imagepart">
					<center>
						<img src="Images/WordCloud_18-24Persons.png" alt="Snow" style="width:100%">
						<figcaption><b><i>Figure 3(a).4 WordClouds representations of labels accociated to Person19 - Person24. </i></b></figcaption>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>
						<ul>
							<li>Here we can see a pattern or relation among the persons listed above the commen label seems to be gClamp. </li>
						</ul>

						<li>The image below represents the WordCloud distribution accross next six persons. </li>
					</ul>
				</div>
				
				<div class="imagepart">
					<center>
						<img src="Images/WordCloud_24-30Persons.png" alt="Snow" style="width:100%">
						<figcaption><b><i>Figure 3(a).5 WordClouds representations of labels accociated to Person25 - Person30. </i></b></figcaption>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>
						<li>The image below represents the WordCloud distribution accross further next six persons. </li>
					</ul>
				</div>
				
				<div class="imagepart">
					<center>
						<img src="Images/WordCloud_30-36Persons.png" alt="Snow" style="width:100%">
						<figcaption><b><i>Figure 3(a).6 WordClouds representations of labels accociated to Person31 - Person36. </i></b></figcaption>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>
						<li>The image below represents the WordCloud distribution accross further final four persons. </li>
					</ul>
				</div>
				
				<div class="imagepart">
					<center>
						<img src="Images/WordCloud_36-40Persons.png" alt="Snow" style="width:100%">
						<figcaption><b><i>Figure 3(a).7 WordClouds representations of labels accociated to Person37 - Person40. </i></b></figcaption>
					</center>
				</div>
				
				<div  class="mycontent">
					<ul>
						<li> The image below (Figure 3(a).8) shows the object distribution across the 40 people along with their count of occurrences in a heatmap.  </li>
					</ul>
				</div>
				
				
				<div class="imagepart">
					<center>
						<figure>
							<img src="Images/Persons_VS_LabelsDistribution.png" alt="Heatmap for Persons vs. Labels" style="width:130%; margin-left:-10%;">
							<figcaption><b><i>Figure 3(a).8 Persons vs. Labels distribution. </i></b></figcaption>
						</figure>
					</center>
				</div>
			</span>
		</p>
		<br/>
		<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;margin-left:.25in;background:white'>
			<b style='mso-bidi-font-weight:normal'>
				<i style='mso-bidi-font-style:normal'>
					<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:white'>
						<div class="mycontent">
							B) Identify groups of people that have object(s) in common. Please limit your answer to 10 images and 500 words
						</div>
					</span>
				</i>
			</b>
		</p>
		<br>
		<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;margin-left:.25in;background:white'>	
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
				<div class="mycontent">
					We used networks library in python to create a ntework graph and also used NodesAndLinkedEdges library to link objects to correcponding persons.
					<br/>
					<b>Process: </b>
					<ul>
						<li> From the manually classified objects, we have grouped the objects which are common to the corresponding persons and stored it into a dataframe.</li>
						<li> We used Python 'dictionary' to store each object which is associated to many persons as key values pairs. Here key is object and value as list of persons associated to that object i.e for example ({'hairclip':('person1','person2'...)})</li>
						<li> Then, we passed the key values pairs from the above dictionary into the network graph one by one and established link connections between the objects and persons.</li>
						<li> To visualize the link connections we used 'bokeh' library in Python. It helps in interactive visualisation of connections between the objects and persons associated to it.</li>
						<li> Below we can see an interactive plot which represents the connections. In the <I>Top Row</I> we can see persons listed as nodes and in <i>Bottom Row</i> we can see the objects listed as another set of nodes. </li>
					</ul>
				</div>
				
				<div class="interactiveImagePart">
					<center>
						<iframe class="ifnetworkclss" src="Plots/1_object_common.html"></iframe>
						<figcaption><b><i>Figure 3(b).1 Interactive Plot for Objects to Persons. </i></b></figcaption>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>
						<ul>
							<li> In the above plot when any of the <i>Top Row</i> node is selected, it shows its the corresponding connection to the objects. This shows at least one object common to the persons group. </li>
						</ul>
						<li> Further to identify the persons who have two or more objects in common, we iterated over the above created 'dictionary' to identify whether the same group of perople have two objects in common or not. </li>
						<li> With two objects as common we could find that there are 158 groups of persons who have two or more objects in common. </li>
						<li> Below we are visualising one such group in an interactive plot who have two objects in common. </li>
					</ul>
				</div>
				
				<div class="interactiveImagePart">
					<center>
						<iframe class="ifnetworksmallclss" src="Plots/2_objects_common.html"></iframe>
						<figcaption><b><i>Figure 3(b).2 Interactive Plot for two Objects. </i></b></figcaption>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>
						<li> Next, to identify the group who have three or more objects in common, we further iterated over the 'dictionary' with constraints as three objects per person and grouped them. </li>
						<li> We could find that there are 47 groups who have three or more persons in common. </li>
						<li> With the help of interactive plot given below, we can see three objects that are common to person's group. </li>
					</ul>
				</div>
				
				<div class="interactiveImagePart">
					<center>
						<iframe class="ifnetworksmallclss" src="Plots/3_objects_common.html"></iframe>
						<figcaption><b><i>Figure 3(b).3 Interactive Plot for three Objects. </i></b></figcaption>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>
						<li> Next,we tried to identify the group who have three or more objects in common. We iterated over entire 'dictionary' three times. The first iteration gives us two object pair groups, the second iteration gives us three object pair groups and the third iteration gives us four object pair groups.</li>
						<li> We identified that there are 19 groups who have four or more person's groups in common</li>
						<li> With the help of interactive plot given below, we can see four objects that are common to person's group.</li>
					</ul>
				</div>
				
				<div class="interactiveImagePart">
					<center>
						<iframe class="ifnetworksmallclss" src="Plots/4_objects_common.html"></iframe>
						<figcaption><b><i>Figure 3(b).4 Interactive Plot for four Objects. </i></b></figcaption>
					</center>
				</div>
			</span>
		</p>
		<br>
		<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;margin-left:.25in;background:white'>
			<b style='mso-bidi-font-weight:normal'>
				<i style='mso-bidi-font-style:normal'>
					<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:white'>
						<div class="mycontent">
							4. Which group do you think is the most likely group with the "totem"? What is your rationale for that assessment? Please limit your response to 5 images and 300 words.
						</div>
					</span>
				</i>
			</b>
		</p>
		<br>
		<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;margin-left:.25in;background:white'>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
				<div class="mycontent">
					From the hint given in the challenge, we came to know that the analysis of the cyber event gave a strong indication that a subgroup of eight individuals were behind the bug. We rule out the cases where less than 8 persons have an item.
					<br/><br/>
					Below image shows the count of person's per group who have object in common:
				</div>
			
				<div class="imagepart">
					<center>
						<img src="Images/ObjectsAssociatedToPersons.png" alt="Snow" style="width:100%">
						<figcaption><b><i>Figure 4.1 Count of Persons per object. </i></b></figcaption>
					</center>
				</div>
			
				<div class="mycontent">
					If an outsider person has the totem it does not serve the purpose of secret signal anymore. Thus we filter the scenarios where an item is present exactly among 8 persons. So, we have ruled out the cases where more than eight persons have a common item. We have five such items which are shown in Figure 4.2.
				</div>
				
				<div class="imagepart">
					<center>
						<img src="Images/Potential_totem_items.png" alt="Snow" style="width:100%">
						<figcaption><b><i>Figure 4.2 Potential totem's perperso. </i></b></figcaption>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>
						<li> From the above plot, it is worth noting here that the persons 5, 9, 10, 13, 16, 18, 19, 24, 26, 27, 29, 32, 33 do not have any of these 5 items and therefore are not among the secret group. </li>
						<li> Based on the number of items each person has among these 5 potential items, we calculated the probability of each of the 40 persons belonging to the secret group, shown in the Figure 4.3.</li>
					</ul>
				</div>
				
				<div class="imagepart">
					<center>
						<iframe class="ifrbarplt" src="Plots/Probability_person_belonging_to secret_group.html" ></iframe>
						<figcaption><b><i> Figure 4.3 Probability that a person belongs to crime group. </i></b></figcaption>
					</center>
				</div>
				
				<div class="mycontent">
					We see that there are 11 persons with a probability of at least 0.4. It is highly likely that the majority of members of the secret group are among these 11. <i>1, 2, 4, 11, 12, 15, 17, 20, 30, 36, 38</i>. Based on these probabilities, we calculated how likely it is that an item is a totem, by simply multiplying the probabilities of persons who have the item.
					<br/>
					<ul>
						<li>'noisemaker': 0.00049, </li>
						<li>'hairClip': 0.00037,</li>
						<li>'rainbowPens': 0.00012,</li>
						<li>'rubiksCube': 6.144e-05,</li>
						<li>'canadaPencil': 1.536e-05</li>
					</ul>
					We see it is more likely that the 'noisemaker' is the totem. Interestingly, among the 11 persons with high probability, the persons 1, 2, 11, 12, 15, 20, 36 all have the 'noisemaker' object. Further strengthening the idea that the 'noisemaker' is the totem and the group of 8 persons 1, 2, 11, 12, 15, 20, 36, 37 are the secret group.
				</div>
			</span>
		</p>
		<br/>
		<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;margin-left:.25in;background:white'>	<b style='mso-bidi-font-weight:normal'>
				<i style='mso-bidi-font-style:normal'>
					<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:white'>
						<div class="mycontent">
							5. Did you choose to use the object recognition model results provided or use your own machine learning algorithm? Why did you make that choice? What was the biggest challenge you faced?&#8239;Please limit your response to 3 images and 300 words.
						</div>
					</span>
				</i>
			</b>
		</p>
		<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;margin-left:.25in;background:white'>
			<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
				<div class="mycontent">
					Yes, we chose to use the object recognition model results provided for the purpose of the visualization task. We decided to use the given model results as our primary task was to vizualize these results for better interpretation.<br/><br/>
					The biggest challenge that we faced was to perform the vizulization task. We developed an application which is used to re-classify and compare the classification results of the YOLO algorithm. The images that are classified by the YOLO algorithm had sufficient details for us to evalute its performance. With help of our application which is based on python, when an image is opened, there is a provision for drawing bounding boxes and labeling them with the available Label names within the training data. In this application when an image is opened, its corresponding bounding boxes (which are provided by the YOLO algorithm) are projected on them. Thus, this made it easier for us to know whether the image classification was accurate. If the classification is incorrect then we can delete or resize or re-label all the present bounding boxes. With the help of this application we are also able to draw a new bounding box on the image if required. After saving the changes we can immediately know the overall classification and mis-classication rate through our application.<br/><br/>
					The three images to justify our approach are:<br/>
					<ul>
						<li> This image is of Person1_1. In this image [Figure 5.1(a)] as we can see a there are around 6 labels classified by the YOLO algorithm, but none of them is correct. The other image [Figure 5.1(b)] of the same person, shows how we can delete the irrelevant bounding boxes and create the new one using the application. </li>
					</ul>
				</div>
				
				<div class="imagepart">
					<center>
						<figure>
							<img src="Images/1st_img_no_correct_label.png", alt="Bounding boxes represented by YOLO Algorithm", style="width:100%;margin-top:0%">
							<figcaption><b><i> Figure 5.1(a) Bounding boxes represented by the YOLO algorithm. </i></b></figcaption>
						</figure>
						<figure>
							<img src="Images/1st_img_correct_label_manually.png", alt="Bounding boxes rectified manually with the help of our Application", style="width:100%;margin-top:0%">
							<figcaption><b><i> Figure 5.1(b) Bounding boxes rectified manually with the help of our application. </i></b></figcaption>
						</figure>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>
						<li> This image is of Person15_8. In this image [Figure 5.2(a)] as we can see a there is not a single label classified by the YOLO algorithm, whereas there is a correct label. The other image [Figure 5.2(b)] of the same person, shows how we manually did the bounding box around the object and classified its label name using the application. </li>
					</ul>
				</div>
				
				<div class="imagepart">
					<center>
						<figure>
							<img src="Images/2nd_img_no_label_identified.png", alt="No bounding box identified by YOLO Algorithm", style="width:100%;margin-top:0%">
							<figcaption><b><i> Figure 5.2(a) No bounding box identified by the YOLO algorithm. </i></b></figcaption>
						</figure>
						<figure>
							<img src="Images/2nd_img_label_detected_manually.png", alt="Drew one correct bounding box manually with the help of our Application", style="width:100%;margin-top:0%">
							<figcaption><b><i> Figure 5.2(b) Drew one correct bounding box manually with the help of our application. </i></b></figcaption>
						</figure>
					</center>
				</div>
				
				<div class="mycontent">
					<ul>
						<li> This image is of Person33_5. In this image [Figure 5.3(a)] as we can see a there are around 6 labels classified by the YOLO algorithm, whereas there only one correct label. The other image [Figure 5.3(b)] of the same person, shows how we manually re-sized the bounding box around the correct object and deleted the rest of the irrelevant labels using the application. </li>
					</ul>
				</div>
				
				<div class="imagepart">
					<center>
						<figure>
							<img src="Images/3rd_img_multiple labels.png", alt="Multiple bounding boxes are identified by YOLO Algorithm", style="width:100%;margin-top:0%">
							<figcaption><b><i> Figure 5.3(a) Multiple bounding boxes are identified by the YOLO algorithm. </i></b></figcaption>
						</figure>
						<figure>
							<img src="Images/3rd_img_only_one _resize_manually.png", alt="Rectified the correct bounding box and deleted the rest of the irrelevant ones manually with the help of our Application", style="width:100%;margin-top:0%">
							<figcaption><b><i> Figure 5.3(b) Rectified the correct bounding box and deleted the rest of the irrelevant ones manually with the help of our application. </i></b></figcaption>
						</figure>
					</center>
				</div>
			</span>
		</p>
	</div>
</body>

</html>
