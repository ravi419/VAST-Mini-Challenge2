<html xmlns:v="urn:schemas-microsoft-com:vml" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:w="urn:schemas-microsoft-com:office:word" xmlns:m="http://schemas.microsoft.com/office/2004/12/omml" xmlns="http://www.w3.org/TR/REC-html40">

<head>
	<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
	<meta name=ProgId content=Word.Document>
	<meta name=Generator content="Microsoft Word 15">
	<meta name=Originator content="Microsoft Word 15">
	<link rel=File-List href="VAST%20Challenge%202020%20MC2%20Answer%20Sheet_files/filelist.xml">
	<title>This form is a web page which was created in MS WORD and therefore can be easily edited that way</title>
	<link rel=themeData href="VAST%20Challenge%202020%20MC2%20Answer%20Sheet_files/themedata.thmx">
	<link rel=colorSchemeMapping href="VAST%20Challenge%202020%20MC2%20Answer%20Sheet_files/colorschememapping.xml">
	<style>
		.mycontent{
		      max-width: 1000px !important;
		      margin-left: auto;
		      margin-right: auto;
		      font-family: 'Montserrat';
		      font-size: 18px;
		      line-height: 1.7;
		      padding-right: 15px;
		      padding-left: 15px;
		}
		.imagepart{
		      max-width: 100% !important;
		      margin-left: auto;
		      margin-right: auto;
		}
		.column {
		  float: right;
		  width: 33.3%;
		  padding-right:200px;
		  padding-top:50px;
		}
		
		/* Clear floats after image containers */
		.row::after {
		  content: "";
		  clear: both;
		  display: table;
		  padding-top:-100px
		}
		.ifrclss{
			width:60%;
			height:70%;
			margin-top:2%;
		}
		.ifnetworksmallclss{
			width:60%;
			height:60%;
			margin-top:2%;
			
		}
		.ifnetworkclss{
			width:110%;
			height:90%;
			margin-top:2%;
			margin-bottom:2%;
			
			
		}
		
		iftwobarplt{
			width:30%;
			height:60%;
			margin-top:2%;
		}
		.ifrbarplt{
			width:90%;
			height:80%;
			margin-top:2%;
			margin-bottom:2%;
		}
		.figcls{
			text-align:center;
			margin-top:-0.5%;
			margin-bottom:2%;
		}
	</style>
</head>

<body lang=EN-US link=blue vlink=purple style='tab-interval:.5in'>
	<div class=WordSection1>
		<h2 align=center style='margin:0in;margin-bottom:.0001pt;text-align:center'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin;font-weight:normal;mso-bidi-font-weight:
bold'>Entry Name:<span style='mso-spacerun:yes'>  </span></span><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:
yellow'>&quot;OVGU-abc-MC2&quot;</span><span style='font-size:11.0pt;
font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:
"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'><o:p></o:p></span></h2>
		<h2 align=center style='margin:0in;margin-bottom:.0001pt;text-align:center'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin'>VAST Challenge </span><i><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;
background:yellow;mso-highlight:white;mso-bidi-font-weight:normal'>2020</span></i><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin'><br>
<u>Mini-Challenge 2</u><o:p></o:p></span></h2>
		<h3 style='margin:0in;margin-bottom:.0001pt'><span style='font-size:11.0pt;
font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:
"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'><o:p>&nbsp;</o:p></span></h3>
		<h3 style='margin:0in;margin-bottom:.0001pt'><span style='font-size:11.0pt;
font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:
"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'><o:p>&nbsp;</o:p></span></h3>
		<h3 style='margin:0in;margin-bottom:.0001pt'><span style='font-size:11.0pt;
font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:
"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>Team
Members:<o:p></o:p></span></h3>
		<h3 style='margin:0in;margin-bottom:.0001pt'><i style='mso-bidi-font-style:
normal'><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;
mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";
mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:
yellow;mso-highlight:white;font-weight:normal;mso-bidi-font-weight:bold'><span
style='mso-spacerun:yes'>  </span><o:p></o:p></span></i></h3>
		<p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;
mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:
minor-latin;background:white;mso-highlight:yellow;mso-bidi-font-style:italic'>Ravi Mallikarjun, 
Otto von Guericke University Magdeburg , </span><a href="mailto:ravi.chennaboina@st.ovgu.de"><span style='font-size:11.0pt;
font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:
yellow;mso-bidi-font-style:italic'>ravi.chennaboina@st.ovgu.de</span></a><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;
background:yellow;mso-highlight:yellow;mso-bidi-font-style:italic'><span
style='mso-spacerun:yes'>     </span>PRIMARY
			<br>Niha Mohanty, Otto von Guericke University Magdeburg,</span><a href="mailto:niha.mohanty@st.ovgu.de"><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;
mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:
minor-latin;background:white;mso-highlight:yellow;mso-bidi-font-style:italic'>niha.mohanty@st.ovgu.de</span></a><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;
background:yellow;mso-highlight:yellow;mso-bidi-font-style:italic'> </span><i><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'><br
style='mso-special-character:line-break'>
<br>Under Supervision of : DR.Monique Meuschke,Otto von Guericke University Magdeburg,</span><a href="mailto:meuschke@isg.cs.uni-magdeburg.de"> 
<![if !supportLineBreakNewLine]><br style='mso-special-character:line-break'>
<![endif]></span></i><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;
mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:
minor-latin'><o:p></o:p></span>
		</p>
		<p class=MsoNormal><b style='mso-bidi-font-weight:normal'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>Student
Team:</span></b><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;
mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:
minor-latin'> <b style='mso-bidi-font-weight:normal'><span
style='mso-spacerun:yes'> </span>
			</b><i style='mso-bidi-font-style:normal'><span
style='background:white;mso-highlight:yellow'>YES </span><o:p></o:p></i>
			</span>
		</p>
		<p class=MsoNormal><i style='mso-bidi-font-style:normal'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'><o:p>&nbsp;</o:p></span></i>
		</p>
		<h3 style='margin:0in;margin-bottom:.0001pt'><span style='font-size:11.0pt;
font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:
"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>Tools
Used:<o:p></o:p></span></h3>
		<p class=MsoNormal><i><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;
mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:
minor-latin;background:yellow;mso-highlight:yellow'>Provide a list of tools
used.<span style='mso-spacerun:yes'>  </span>Examples:<o:p></o:p></span></i>
		</p>
		<p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;
mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:
minor-latin;background:yellow;mso-highlight:white;mso-bidi-font-style:italic'>Python<o:p></o:p></span>
		</p>
		<p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;
mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:
minor-latin;background:yellow;mso-highlight:white;mso-bidi-font-style:italic'>R Programming<o:p></o:p></span>
		</p>
		<p class=MsoNormal><span class=SpellE><span style='font-size:11.0pt;font-family:
"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin;background:yellow;mso-highlight:
yellow;mso-bidi-font-style:italic'>PLotly , Bokeh library for interactive Visualisation and Networkx for Edge ,Node graphs</span></span><span style='font-size:
11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;
mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:
yellow;mso-highlight:yellow;mso-bidi-font-style:italic'>, we also created an application for drawing the bounding box and giving the corresponding label to it. The basic structure was taken from
<a href=""></a>  we modified the application with more advanced features and we also tried integrated it with the python code which calculates the correct classification and incorrect classifications.  </span><span style='font-size:11.0pt;font-family:
"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:
minor-latin;background:yellow;mso-highlight:yellow'></span><span style='font-size:11.0pt;font-family:
"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin;mso-bidi-font-style:italic'><o:p></o:p></span>
		</p>
		<p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;
mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:
minor-latin;mso-bidi-font-style:italic'><o:p>&nbsp;</o:p></span>
		</p>
		<p class=MsoNormal><b style='mso-bidi-font-weight:normal'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;
mso-bidi-font-style:italic'>Approximately how many hours were spent working on
this submission in total?<o:p></o:p></span></b>
		</p>
		<p class=MsoNormal><i><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;
mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:
minor-latin;background:yellow;mso-highlight:yellow'>Provide an estimate of the
total number of hours worked on this submission by your entire team.</span></i><b style='mso-bidi-font-weight:normal'><span style='font-size:11.0pt;font-family:
"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin;mso-bidi-font-style:italic'><o:p></o:p></span></b>
		</p>
		<p class=MsoNormal><b style='mso-bidi-font-weight:normal'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;
mso-bidi-font-style:italic'><o:p>&nbsp;</o:p></span></b>
		</p>
		<p class=MsoNormal><b style='mso-bidi-font-weight:normal'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;
mso-bidi-font-style:italic'>May we post your submission in the Visual Analytics
Benchmark Repository after VAST Challenge 2020 is complete? </span></b><i style='mso-bidi-font-style:normal'><span style='font-size:11.0pt;font-family:
"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin;background:yellow;mso-highlight:
yellow'>Please enter a YES or NO</span></i><b style='mso-bidi-font-weight:normal'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;
mso-bidi-font-style:italic'><o:p></o:p></span></b>
		</p>
		<p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;
mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:
minor-latin;mso-bidi-font-style:italic'><o:p>&nbsp;</o:p></span>
		</p>
		<p class=MsoNormal><b><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;
mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:
minor-latin;mso-bidi-font-style:italic'>Video <o:p></o:p></span></b>
		</p>
		<p class=MsoNormal><i style='mso-bidi-font-style:normal'><span
style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;
background:yellow;mso-highlight:yellow'>Provide a link to your video.<span
style='mso-spacerun:yes'>  </span>Example:<o:p></o:p></span></i>
		</p>
		<p class=MsoNormal><a href="http://www.westbirmingham.ac.uk/uwb-smith-mc2-video.wmv"><b
style='mso-bidi-font-weight:normal'><span style='font-size:11.0pt;font-family:
"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin;background:yellow;mso-highlight:
yellow'>http://www.westbirmingham.ac.uk/uwb-smith-mc2-video.wmv</span></b></a><b style='mso-bidi-font-weight:normal'><span style='font-size:11.0pt;font-family:
"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin'> <o:p></o:p></span></b>
		</p>
		<p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;
mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:
minor-latin'>&nbsp;<o:p></o:p></span>
		</p>
		<div style='mso-element:para-border-div;border:none;border-bottom:solid windowtext 1.0pt;
mso-border-bottom-alt:solid windowtext .75pt;padding:0in 0in 1.0pt 0in'>
			<p class=MsoNormal style='border:none;mso-border-bottom-alt:solid windowtext .75pt;
padding:0in;mso-padding-alt:0in 0in 1.0pt 0in'><span style='font-size:11.0pt;
font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin'><o:p>&nbsp;</o:p></span>
			</p>
		</div>
		<p class=MsoNormal><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;
mso-ascii-theme-font:minor-latin;mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:
minor-latin'><o:p>&nbsp;</o:p></span>
		</p>
		<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto'><b style='mso-bidi-font-weight:normal'><span style='font-size:11.0pt;font-family:
"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:
"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;
color:windowtext'><div class="mycontent">Questions<o:p></o:p></span></b>
		</p>
	</div>
	<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
margin-left:.25in;background:white'><span style='font-size:11.0pt;font-family:
"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:
"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
<div class="mycontent">
Given the images and text files as well as machine learning outputs, use visual
analytics to answer the questions below to improve and understand machine
learning outputs and track provenance, uncertainty, and confidence in machine
learning results. Ultimately, you must link multiple data types to identify the
group CGCS is seeking.<span style='mso-spacerun:yes'>  </span></span><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin;color:windowtext;mso-color-alt:
windowtext'><o:p></o:p></span>
	</p>
	</div>
	<br>
	<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
margin-left:.25in;background:white'><b style='mso-bidi-font-weight:normal'><i
style='mso-bidi-font-style:normal'><span style='font-size:11.0pt;font-family:
"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:
"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;
background:white;mso-highlight:white'><div class="mycontent">
1. Examine the outputs from the model either from the detection results provided or the
results from a model you chose. Which objects were identified well by the model
and which were not? Please limit your answer to 5 images and 250 words.
images here. </span></i></b><b style='mso-bidi-font-weight:normal'><i
style='mso-bidi-font-style:normal'><span style='font-size:11.0pt;font-family:
"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:
"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;
color:windowtext;mso-color-alt:windowtext'><o:p></o:p></span></i></b>
	</p>
	<br>
	</div>
	<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
margin-left:.25in;background:white'><span style='font-size:11.0pt;font-family:
"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:
"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
<div class="mycontent">
We have used the YOLO algorithm output to examine the results:<br> 
Approach: To evaluate any outcome, there should exist a <i>Ground Truth</i>. In order to generate the ground truth, we created a BoundingBox Labeling application
through which we have labeled all the 40 person's images manually ,the application outputs a csv file containing the BoundingBox measurements i.e x,y points and width,height of the box along with
the corresponding label and filename. <br>
 <ul>
  <!--<li> Firstly, we compare the distrubution of the labeles accross the YOLO algorithm and the manually labeled files.-->
  </div> 
  <div class="imagepart">
	  <center>
		  <iframe class="ifrbarplt" src="Plots/Counts_Of_Yolo_Predictions.html" ></iframe>
	  </center>	
	  <center>
		  <iframe class="ifrbarplt" src="Plots/Counts_Of_Manual_Predictions.html" ></iframe>
	  </center>
   <!--<figure>
	<img src="Plots/Lable_Comparision_YOLO_VS_Manual.png" alt=" Count of YOLO predicted Lables vs Count of Manually Assigned Lables" style="width:100%;margin-top:0%">
		<figcaption class="figcls"> Fig.1 Count of YOLO predicted Lables vs Count of Manually Assigned Lables .
		</figcaption> 
   </figure>-->
   </div> 
   <div class="mycontent">
	<br>
	<ul>
		<li>On X-axis: Object Lables</li>
		<li>On Y-axis: No of Occurences</li>
		<li>From the above Barchart we can clearly see that YOLO algorithm has completely did not classify or missclassified few object class labeles namely <i>BrownDie, FoamDart, GiftBag etc.</i></li> 
	</ul>
  </li>
  <br>
  <li>Secondly, we check the number of times an Object lable is missclassified by the YOLO algorithmm. Here, we use confusion martix to show missclassification of an object.
  </div>
	<div class="imagepart">
		
		<figure>
			<img src="Plots/ConfusionMatrix_Actual_VS_Predicted.png" alt=" Count of YOLO predicted Lables vs Count of Manually Assigned Lables" style="width:100%;margin-top:0%">
				<figcaption class="figcls"> Fig.2 Confusion matrix representation of missclassifications .
				</figcaption> 
		</figure>
	</div>
	<div class="mycontent">
	<br>
	<ul>
		<li>On X-axis: Yolo Classified Lables</li>
		<li>On Y-axis: Actual Lables</li>
		<li>From the above Heatmap we can see the number of times an actual label is missclassified by YOLO algorithm.</li>
		<li>The most missclassified objects by YOLO are PaperPlate is missclassified as pumpkinNotes and PartyFavor as Cloud sign.</li>
		<li>Lets inspect the reason behind this missclassification of PartyFavor as CloudSign
	</div>
		<div class="imagepart">
			 <div class="row">
				<div class="column">
					<img src="Plots/partyFavor.jpg" alt="Snow" style="width:100%">
						<figcaption class="figcls"> Fig.3 PartyFavor.</figcaption>
				</div>
				<div class="column">
					<img src="Plots/cloudSign.jpg" alt="Forest" style="width:100%;padding-right:500px">
						<figcaption class="figcls" > Fig.3 CloudSign.</figcaption>
				</div>
			</div>
		</div>
		</li>
		<br>
		<div class="mycontent">
		<li>From the above images we can see that the YOLO algorithm has confused with the <i>Golden</i> structure of PartyFavor as CloudSign.</li>
	</ul>
  </li>
  <li>Further, we tried to visualise the objects that are correctly and incorrectly classified images by the YOLO algorithm</li>
</ul>  .<span style='mso-spacerun:yes'>  </span></span><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin;color:windowtext;mso-color-alt:
windowtext'><o:p></o:p></span>
	</p>
	</div>
	<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
margin-left:.25in;background:white'><b style='mso-bidi-font-weight:normal'><i
style='mso-bidi-font-style:normal'><span style='font-size:11.0pt;font-family:
"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:
"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;
background:white;mso-highlight:white'><div class="mycontent">
2. Demonstrate your process for using visual analytics to correct for classification errors in the results. How do you represent confidence and uncertainty? How could the 
	correction process be made more efficient? Please limit your answer to 10 images and 500 words.  </div> </span></i></b><b style='mso-bidi-font-weight:normal'><i
style='mso-bidi-font-style:normal'><span style='font-size:11.0pt;font-family:
"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:
"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;
color:windowtext;mso-color-alt:windowtext'><o:p></o:p></span></i></b>
	</p>
	<br>
	<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;
margin-left:.25in;background:white'><span style='font-size:11.0pt;font-family:
"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:
"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
<div class="mycontent">With the <i>Groud Truth</i> that we prepared earlier, we followed the followed certain analysis steps to determine the classification errors and correcting the missclassifications by our tool 
	<ul>
		<li>After merging the all 40 person's data into a single dataframe, we are checking each person's file with the corresponding <i>Ground Truth</i> file person's name. 
			If the ground truth lable matches with the YOLO algorithm labels further to increase the certainity in the process, we are also examining the area of intersection of YOLO classified image BoundingBox dimentions with the respective <i>Ground Truth</i>
			(Manually Labeled) image BoundingBox dimentions as shown in below image.
			<div class="imagepart">
				<div class="row">
					<img src="Plots/YellowBallon.png" alt="Snow" style="width:100%">
						<figcaption class="figcls"> Fig.1 Yellow Baloon.</figcaption>
				</div>
			</div>
			<br>
				<ul>
					<div class="mycontent">
					<li>Blue BoundingBox: Yolo Classified BBox</li>
					<li>Green BoundingBox: Manually Classified BBox</li>
				</ul>
		  </li>
		  <li>We have used Shape library in Python which compares 2 polygon shapes and results in the area of intersection of both the BoundingBoxes. Here, we have set the criteria of 30% 
				<ul>
					<li> If the intersection area of Manually labeled BoundingBox to the YOLO labeled BoundingBox is greater than 0.3 then we declare that the Image is correctly classified by YOLO 
						 and we store the labele and its count in a Dataframe </li>
					<li> If the intersection area is less than 30% we say the label is missclassified by YOLO algorithm and we store the resultant label in dataframe , below we can see the count of correct, 
						 incorrect classified labels and respective correctly ,incorrectly classified image count.</li>
						 
						 <center>
							 <iframe class="ifrbarplt" src="Plots/YOLO_Classified_Labels.html"></iframe>
							 <figcaption class="figcls"> Fig.2 Correct Classified Lables vs Missclassified Lables count.</figcaption>
						</center>
					<li>From the above image we can see the YOLO classified and missclassified labels count, count of Correctly classified labels are 516 vs Incorrectly Classified Labeles are 2493 </li>
						<center>
							 <iframe class="ifrbarplt" src="Plots/YOLO_Classified_Images.html"></iframe>
							 <figcaption class="figcls"> Fig.3 Manual Image Files vs Yolo Image Files Count.</figcaption>
						</center>
					<li>From the above image we can see YOLO Files(images) count. The count of images which are classified correctly are 223 vs
						 incorrect classifications are 711.</li>
						 
					</div>
					<div class="mycontent" style="margin-top:2em">
					<li> After examining the above results, we tried to run the analysis again, now setting the criteria ass 0% but the count was same for bothe the lables and image files, therefore we can say that the dimentions
						 of correctly classified labels are correct.
					</li>
					<li> Further, we analysed the distrubution of Correctly classified BoundingBox and Labels with the Incorrectly classified Labels but Correct Bounding Box dimentions,
						 along with Bounding box completely not detected in a pie chart  as shown below,
					</div>
					<div class="imagepart">
						 <center>
							 <iframe class="ifrclss" src="Plots/Pie_Chart_BB_Detection_Distrubution.html" ></iframe>
						</center>
					</div>
					</li>
					<div class="mycontent" style="margin-top:2em">
					<li>With the above analysis information we plotted a bar chart where we can know the correctness of YOLO algorithm object classifications results. The bar chart below shows the perormance of YOLO algorithm.
					</div>
					<div class="imagepart">
						<!--<div class="row">
							<img src="Plots/Good_vs_Poor_classification.png" alt="Snow" style="width:100%">
									<figcaption class="figcls"> Fig.4 Good vs POor Classification.</figcaption>
						</div>-->
						<center>
						  <iframe class="ifrbarplt" src="Plots/Good_vs_Poor_Classification.html" ></iframe>
						</center>
					</div>
					</li>
				</ul>
			</li>
		 <div class="mycontent"> 
			<li>To correct the classification errors, we have created an interactive application for the users. This application : 
				<ul><!-- IMAGES to be added by NIHA -->
					<!-- Please Add 3-4 Images of the application along with a brief description , H ere ii have added bullet point descriptions u caan modify this txt and add images-->
					<li> The application allows the user to browse to the directory of the images.</li>
					<li> The user is then shown the list of missclassified files.</li> 
					<li> When the first image is loaded on the canvas, its corresponding YOLO classified Labels are also projected on the image along with the BoundingBox measurements from the corresponding .csv.
					<li> The bounding boxes are color coded inorder to give them a distinction mark.</li>
					<li> On the right side of the application, the label names of those color encoded bounding box are shown.</li>
					<li> The user has complete access to the bounding boxes. The user can verform the following operations:
						<ul>
							<li> <b> DRAW - </b>If there are no bounding boxes detected by YOLO Algorithm on an image, the user can draw one and label it accordingly.</li>
							<li> <b> DELETE - </b>If there are irrelevant bounding boxes, the user can delete them.</li>
							<li> <b> RESIZE - </b>If the bounding boxes are not of accurate size given to the image, the user re-size them.</li>
							<li> <b> EDIT - </b>If the user gave a wrong label name to a drawn bounding box, then he/she can re-lable it by editing the labels.</li>
						</ul>
					</li>
					<li> Once the image is labeled, the filename, BoundingBox ,label are stored in the csv file from which it has been fetched.</li>
					<li> We provide an option for the user to run the above discussed analysis and the result will be the increase in Correct classification by 1</li>
					<li> The application also has the provision of zooming (+/-) the images to give better insight on the image.</li>
				</ul>
			</li>
		</div>

<span style='mso-spacerun:yes'>  </span><span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:
minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:
minor-latin;mso-bidi-theme-font:minor-latin;color:windowtext;mso-color-alt:
windowtext'><o:p></o:p></span>

</div>
	<div class="mycontent">	<i><b>3. Characterize the distribution of objects across the forty people.</b></i>
		<br>	<i>a. Which people have which objects? Please limit your answer to 8 images and 250 words.</i>
		<br>To analyse the object to person's distrubution we used wordcloud library in python. The process is discussed below,
		<ol>
			<li>From the manually classified data , we extracted persons data along with the objects (labels) and number of times the label linked to that person</li>
			<li>Store the labels in a list along with multiple the occurances.</li>
			<li>Join all the elements in the list and convert the joined elements into a single string</li>
			<li>Pass the joined string into the WordCloud library and generate the WordCloud and plot it</li>
			<li>Repeat the process from step one over all 40 persons and store it in a directory</li>
		</ol>
		<ul>
			<li>The image below represents the WordCloud distrubution accross first six persons
				<div class="imagepart">
					<div class="row">
						<img src="Plots/WordCloud_1-6Persons.png" alt="Snow" style="width:100%">
						<figcaption class="figcls">Fig.1 WordClouds representations of labels accociated to Persons_1 - Persons_6.</figcaption>
					</div>
				</div>
				<ul>
					<li>From the above image we can see that WordCloud represents the maximum occured Lable with a big font size .Therefore we can see, Person1 has trophy as maximum occured word , for Person2 has almost even distrubution of the labels etc.</li>
				</ul>
			</li>
			<li>The image below represents the WordCloud distrubution accross second six persons
				<div class="imagepart">
					<div class="row">
						<img src="Plots/WordCloud_6-12Persons.png" alt="Snow" style="width:100%">
						<figcaption class="figcls">Fig.2 WordClouds representations of labels accociated to Persons_7 - Persons_12.</figcaption>
					</div>
				</div>
				<ul>
					<li>From the WordCloud image of Person12 we can see less associated labels but relatively high occurances</li>
				</ul>
			</li>
			<li>The image below represents the WordCloud distrubution accross next six persons
				<div class="imagepart">
					<div class="row">
						<img src="Plots/WordCloud_12-18Persons.png" alt="Snow" style="width:100%">
						<figcaption class="figcls">Fig.3 WordClouds representations of labels accociated to Persons_13 - Persons_18.</figcaption>
					</div>
				</div>
				<ul>
					<li>The Person15 has more labeles associated but relatively low occurances</li>
				</ul>
			</li>
			<li>The image below represents the WordCloud distrubution accross further next six persons
				<div class="imagepart">
					<div class="row">
						<img src="Plots/WordCloud_18-24Persons.png" alt="Snow" style="width:100%">
						<figcaption class="figcls">Fig.4 WordClouds representations of labels accociated to Persons_19 - Persons_24.</figcaption>
					</div>
				</div>
				<ul>
					<li>Here we can see a pattern or relation among the persons listed above the commen label seems to be gClamp</li>
				</ul>
			</li>
			<li>The image below represents the WordCloud distrubution accross next six persons
				<div class="imagepart">
					<div class="row">
						<img src="Plots/WordCloud_24-30Persons.png" alt="Snow" style="width:100%">
						<figcaption class="figcls">Fig.5 WordClouds representations of labels accociated to Persons_25 - Persons_30.</figcaption>
					</div>
				</div>
			</li>
			<li>The image below represents the WordCloud distrubution accross further next six persons
				<div class="imagepart">
					<div class="row">
						<img src="Plots/WordCloud_30-36Persons.png" alt="Snow" style="width:100%">
						<figcaption class="figcls">Fig.6 WordClouds representations of labels accociated to Persons_31 - Persons_36.</figcaption>
					</div>
				</div>
				<ul>
					<li>Here we can see a pattern of Totem (Turtle) occurances among the above persons</li>
				</ul>
			</li>
			<li>The image below represents the WordCloud distrubution accross further final five persons
				<div class="imagepart">
					<div class="row">
						<img src="Plots/WordCloud_36-40Persons.png" alt="Snow" style="width:100%">
						<figcaption class="figcls">Fig.7 WordClouds representations of labels accociated to Persons_37 - Persons_40.</figcaption>
					</div>
				</div>
			</li>
		</ul>
	</div>
	<br>
	<div class="mycontent">	<i><b>b. Identify groups of people that have object(s) in common. Please limit your answer to 10 images and 500 words..</b></i>
		<br>
		<br>We used networkx library in python to create a ntework graph and also used NodesAndLinkedEdges library to link objects to correcponding persons.	<i>Process: </i>
		<ul>
			<li>From the manually classified objects, we have grouped the objects which are common to the corresponding persons and stored it into a dataframe.</li>
			<li>We used python 'dictionary' to store each object which is associated to many persons as key values pairs, here Key is object and pairs as person's associated to that object i.e for example ({'hairclip':('person1','person2'...)})</li>
			<li>Then, we passed the key values pairs from the above dictionary into the network graph one by one and established link connections between the objects and persons.</li>
			<li>To visualise the link connections we used 'bokeh' library in python ,it helps in interactive visualisation of connections between the objects and persons associated to it.</li>
			<li>Below we can see an interactive plot which represents the connections, in the
				<I>Top Row</I> we can see persons listed as nodes and in <i>Bottom Row</i> we can see the objects listed as another set of nodes.</li>
			<center>
				<iframe class="ifnetworkclss" src="Plots/1_object_common.html"></iframe>
			</center>
			<ul>
				<li>In the above plot when selected anyone of the <i>Top Row</i> node it shows the corresponding connection to the object .This shows atleast 1 object common to the persons group</li>
			</ul>
			<li>Further to identify the persons who have 2 or more objects in common, we iterated over the above created 'dictionary' key,values pairs to identify whether the same group of perople have 2 objects in common</li>
			<li>With 2 objects as common we could find that there are 158 groups of persons who have 2 or more objects as common.</li>
			<li>Below we are visualising 1 such group in an interactive plot who have 2 objects in common.</li>
			<center>
				<iframe class="ifnetworksmallclss" src="Plots/2_objects_common.html"></iframe>
			</center>
			<li>Next, to identify the group who have 3 or more objects in common , we further iterated over the 'dictionary' with constraints as 3 objects per person and grouped them .</li>
			<li>We could find that there are 47 groups who have 3 or more person's groups in common</li>
			<li>Below we can 3 objects in common person's group in an interactive plot.</li>
			<center>
				<iframe class="ifnetworksmallclss" src="Plots/3_objects_common.html"></iframe>
			</center>
			<li>Next,we tried to identify the group who have 3 or more objects in common , we iterated over entire 'dictionary' 3 times .The first iteration gets us 2 object pair groups, the 2nd iteration gets us 3 object pair groups and the 2rd iteration gets us 4 object pair groups.</li>
			<li>We identified that there are 19 groups who have 4 or more person's groups in common</li>
			<li>Below we can 4 objects in common person's group in an interactive plot.</li>
			<center>
				<iframe class="ifnetworksmallclss" src="Plots/4_objects_common.html"></iframe>
			</center>
		</ul>
	</div>
	<br>
	<div class="mycontent">	<i><b>4. Which group do you think is the most likely group with the "totem"? What is your rationale for that assessment? Please limit your response to 5 images and 300 words.</b></i>
		<br>
		<br>
		<ul>
			<li>From the hint given in the challenge, we came to know that the analysis of the cyber event gave a strong indication that a subgroup of eight individuals were behind the bug. Therefore,to cut down the total number of groups ,we have to group or seperate people who have groups more that 7 per object.</li>
			<li>Below image shows the count of person's per group who have object in common
				<div class="imagepart">
					<div class="row">
						<img src="Plots/ObjectsAssociatedToPersons.png" alt="Snow" style="width:100%">
						<figcaption class="figcls">Fig.1 Count of Persons per object.</figcaption>
					</div>
				</div>
			</li>
			<li>From the above image we can seperate object groups of strictly eight person's. we have :
				<ul>
					<li>noisemaker</li>
					<li>rainbowPens</li>
					<li>haircClips</li>
					<li>canadaPencil</li>
					<li>rubiksCube</li>
				</ul>
			</li>
			<li>The above five objects groups are in our suspect's list and to find out the group responsible for the bug we can draw manu analogies, i.e
				<ul>
					<li>The group with <i>hairClips</i> can be the responsible group for the crime, why..? If we see the count of hairClips in the actual labeled files , we know that the count is 18. People who wants to meet in secret willmake sure to choose an object which looks different in the environment , as they are meeting in confrences , the irrelavent object,yet a common object could be a hairclip</li>
				</ul>
				<li>Im still looking for a solid proof to find the suspect group ill get back to you in the evening ..</li>
			</li>
		</ul>
	</div>
	<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;margin-left:.25in;background:white'> <b style='mso-bidi-font-weight:normal'>
    <i style='mso-bidi-font-style:normal'>
      <span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;background:white;mso-highlight:white'>
        <div class="mycontent">
          5. Did you choose to use the object recognition model results provided or use your own machine learning algorithm? Why did you make that choice? What was the biggest challenge you faced?&#8239;Please limit your response to 3 images and 300 words.
        </div>
      </span>
    </i>
  </b>
		<b style='mso-bidi-font-weight:normal'>
    <i style='mso-bidi-font-style:normal'>
      <span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin;color:windowtext;mso-color-alt:windowtext'>
        <o:p></o:p>
      </span>
    </i>
  </b>
	</p>
	<p class=MsoNormal style='mso-margin-top-alt:auto;mso-margin-bottom-alt:auto;margin-left:.25in;background:white'>	<span style='font-size:11.0pt;font-family:"Calibri",sans-serif;mso-ascii-theme-font:minor-latin;mso-fareast-font-family:"Times New Roman";mso-hansi-theme-font:minor-latin;mso-bidi-theme-font:minor-latin'>
		<div class="mycontent">
			Yes, we chose to use the object recognition model results provided for the purpose of the visualization task. We decided to use the given model results as our primary task was to vizualize these results for better interpretation.<br/><br/>
			The biggest challenge that we faced was to perform the vizulization task. We developed an application which is used to re-classify and compare the classification results of the YOLO Algorithm. The images that are classified by the YOLO Algorithm had sufficient details for us to evalute its performance. With help of our application which is based on python, when an image is opened, there is a provision for drawing bounding boxes and labeling them with the available Label names within the training data. In this application when an image is opened, its corresponding bounding boxes (which are provided by the YOLO algorithm) are projected on them. Thus, this made it easier for us to know whether the image classification was accurate. If the classification is incorrect then we can delete or resize or re-label all the present bounding boxes. With the help of this application we are also able to draw a new bounding box on the image if required. After saving the changes we can immediately know the overall classification and mis-classication rate through our application.<br/><br/>
			The three images to justify our approach are:<br/>
			<ul>
				<li> This image is of Person1_1. In this image [Fig. 1(a)] as we can see a there are around 6 labels classified by the YOLO Algorithm, but none of them is correct. The other image [Fig.1(b)] of the same person, shows how we can delete the irrelevant bounding boxes and create the new one using the application.
					<div>
						<figure>
							<img src="Images/1st_img_no_correct_label.png", alt="Bounding boxes represented by YOLO Algorithm", style="width:100%;margin-top:0%">
							<figcaption class="figcls"> Fig.1(a) Bounding boxes represented by YOLO Algorithm</figcaption>
						</figure>
						<figure>
							<img src="Images/1st_img_correct_label_manually.png", alt="Bounding boxes rectified manually with the help of our Application", style="width:100%;margin-top:0%">
							<figcaption class="figcls"> Fig.1(b) Bounding boxes rectified manually with the help of our Application</figcaption>
						</figure>
					</div>
				</li>	
				
				<li> This image is of Person14_2. In this image [Fig. 2(a)] as we can see a there is not a single label classified by the YOLO Algorithm, whereas there is a correct label. The other image [Fig.2(b)] of the same person, shows how we manually did the bounding box around the object and classified its label name using the application.
					<div>
						<figure>
							<img src="Images/2nd_img_no_label_identified.png", alt="No bounding box identified by YOLO Algorithm", style="width:100%;margin-top:0%">
							<figcaption class="figcls"> Fig.2(a) No bounding box identified by YOLO Algorithm</figcaption>
						</figure>
						<figure>
							<img src="Images/2nd_img_label_detected_manually.png", alt="Drew one correct bounding box manually with the help of our Application", style="width:100%;margin-top:0%">
							<figcaption class="figcls"> Fig.2(b) Drew one correct bounding box manually with the help of our Application</figcaption>
						</figure>
					</div>
				</li>
				
				<li> This image is of Person33_5. In this image [Fig. 3(a)] as we can see a there are around 6 label classified by the YOLO Algorithm, whereas there only one label which is correct. The other image [Fig.3(b)] of the same person, shows how we manually re-sized the bounding box around the correct object and deleted the rest of the irrelevant labels using the application.
					<div>
						<figure>
							<img src="Images/3rd_img_multiple labels.png", alt="Multiple bounding boxes are identified by YOLO Algorithm", style="width:100%;margin-top:0%">
							<figcaption class="figcls"> Fig.3(a) Multiple bounding boxes are identified by YOLO Algorithm</figcaption>
						</figure>
						<figure>
							<img src="Images/3rd_img_only_one _resize_manually.png", alt="Rectified the correct bounding box and deleted the rest of the irrelevant ones manually with the help of our Application", style="width:100%;margin-top:0%">
							<figcaption class="figcls"> Fig.3(b) Rectified the correct bounding box and deleted the rest of the irrelevant ones manually with the help of our Application</figcaption>
						</figure>
					</div>
				</li>

			</ul>
		</div>
	</span>
	</p>
	</div>
	</div>
</body>

</html>
